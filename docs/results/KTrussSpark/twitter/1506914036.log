/home/i/spark-2.1/bin/spark-submit --class ir.ac.sbu.graph.ktruss.spark.KTrussSpark --total-executor-cores 120 --master spark://alemi-1:7077 /home/i/subgraph-mining/target/subgraph-mining-1.0-jar-with-dependencies.jar hdfs://alemi-1/graph-data/twitter 500 4
[SBM] Input: hdfs://alemi-1/graph-data/twitter, partitionNum: 500, kc: 4
02 Oct 2017 06:43:57,761 WARN - NativeCodeLoader.<clinit>(62) -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
02 Oct 2017 06:43:57,851 WARN - Logging$class.logWarning(66) -  In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
02 Oct 2017 06:43:57,859 WARN - Logging$class.logWarning(66) -  
SPARK_WORKER_INSTANCES was detected (set to '1').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --num-executors to specify the number of executors
 - Or set SPARK_EXECUTOR_INSTANCES
 - spark.executor.instances to configure the number of instances in the spark config.
        
